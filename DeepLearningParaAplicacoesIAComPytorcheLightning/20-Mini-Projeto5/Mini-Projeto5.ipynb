{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Academy</font>\n",
    "# <font color='blue'>Deep Learning Para Aplicações de IA com PyTorch e Lightning</font>\n",
    "\n",
    "## <font color='blue'>Mini-Projeto 5</font>\n",
    "## <font color='blue'>Segmentação de Imagens Médicas com Inteligência Artificial</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DSA](imagens/MP5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalando e Carregando os Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para atualizar um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# pip install -U nome_pacote\n",
    "\n",
    "# Para instalar a versão exata de um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# !pip install nome_pacote==versão_desejada\n",
    "\n",
    "# Depois de instalar ou atualizar o pacote, reinicie o jupyter notebook.\n",
    "\n",
    "# Instala o pacote watermark. \n",
    "# Esse pacote é usado para gravar as versões de outros pacotes usados neste jupyter notebook.\n",
    "!pip install -q -U watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q opencv-python==4.8.0.76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch==2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torchvision==0.15.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Albumentations é uma biblioteca Python para aumento de imagens (dataset augmentation). O aumento de imagem é usado em tarefas de aprendizado profundo e visão computacional para aumentar a qualidade dos modelos treinados. O objetivo do aumento de imagem é criar novas amostras de treinamento a partir dos dados existentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q albumentations==0.4.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-01-20T01:36:23.800876Z",
     "iopub.status.busy": "2023-01-20T01:36:23.800135Z",
     "iopub.status.idle": "2023-01-20T01:36:24.786284Z",
     "shell.execute_reply": "2023-01-20T01:36:24.785165Z",
     "shell.execute_reply.started": "2023-01-20T01:36:23.800838Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import sklearn\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import albumentations as A\n",
    "import albumentations.augmentations.transforms as AT\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from albumentations.pytorch import ToTensorV2, ToTensor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.models import resnext50_32x4d\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Data Science Academy\" --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando e Organizando as Imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T01:36:04.822133Z",
     "iopub.status.busy": "2023-01-20T01:36:04.821332Z",
     "iopub.status.idle": "2023-01-20T01:36:04.852620Z",
     "shell.execute_reply": "2023-01-20T01:36:04.851585Z",
     "shell.execute_reply.started": "2023-01-20T01:36:04.822011Z"
    }
   },
   "outputs": [],
   "source": [
    "# Caminho dos dados\n",
    "pasta_imagens = \"dados\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para os dados organizados\n",
    "dados = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T01:36:39.476015Z",
     "iopub.status.busy": "2023-01-20T01:36:39.475467Z",
     "iopub.status.idle": "2023-01-20T01:36:41.990580Z",
     "shell.execute_reply": "2023-01-20T01:36:41.989557Z",
     "shell.execute_reply.started": "2023-01-20T01:36:39.475976Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loop para iterar através de cada diretório ou arquivo em pasta_imagens\n",
    "for dir_ in os.listdir(pasta_imagens):\n",
    "    \n",
    "    # Concatena o caminho base com o nome do diretório ou arquivo para formar o caminho completo\n",
    "    dir_path = os.path.join(pasta_imagens, dir_)\n",
    "    \n",
    "    # Verifica se o caminho é um diretório\n",
    "    if os.path.isdir(dir_path):\n",
    "        \n",
    "        # Loop para iterar através de cada arquivo dentro do diretório\n",
    "        for filename in os.listdir(dir_path):\n",
    "            \n",
    "            # Concatena o caminho do diretório com o nome do arquivo para formar o caminho completo do arquivo\n",
    "            img_path = os.path.join(dir_path, filename)\n",
    "            \n",
    "            # Anexa o nome do diretório e o caminho completo do arquivo à lista \"dados\"\n",
    "            dados.append([dir_, img_path])\n",
    "    \n",
    "    # Se o caminho não é um diretório, imprime uma mensagem de informação\n",
    "    else:\n",
    "        print(f\"Isso não é uma pasta --> {dir_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o dataframe\n",
    "df_imagens = pd.DataFrame(dados, columns = [\"nome_pasta\", \"caminho_imagem\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T11:20:44.320807Z",
     "iopub.status.busy": "2023-01-19T11:20:44.320352Z",
     "iopub.status.idle": "2023-01-19T11:20:44.338566Z",
     "shell.execute_reply": "2023-01-19T11:20:44.337629Z",
     "shell.execute_reply.started": "2023-01-19T11:20:44.320769Z"
    }
   },
   "outputs": [],
   "source": [
    "# Amostra do dataframe\n",
    "df_imagens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho para a imagem de índice 2\n",
    "df_imagens.caminho_imagem[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T01:36:59.798876Z",
     "iopub.status.busy": "2023-01-20T01:36:59.798421Z",
     "iopub.status.idle": "2023-01-20T01:36:59.833689Z",
     "shell.execute_reply": "2023-01-20T01:36:59.832621Z",
     "shell.execute_reply.started": "2023-01-20T01:36:59.798836Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataframes de imagens e máscaras\n",
    "df_imgs = df_imagens[~df_imagens[\"caminho_imagem\"].str.contains(\"mask\")]\n",
    "df_masks = df_imagens[df_imagens[\"caminho_imagem\"].str.contains(\"mask\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de imagens. O pandas trunca o nome e não podemos ver o final.\n",
    "df_imgs.caminho_imagem[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Não trunca os nomes\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de imagens. Observe o nome de algumas imagens com apenas 1 dígito.\n",
    "df_imgs.caminho_imagem[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de máscaras. Observe o nome de algumas máscaras com apenas 1 dígito.\n",
    "df_masks.caminho_imagem[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uma imagem\n",
    "df_imgs.caminho_imagem[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_imgs.caminho_imagem[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uma máscara\n",
    "df_masks.caminho_imagem[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_masks.caminho_imagem[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T01:36:09.288367Z",
     "iopub.status.busy": "2023-01-20T01:36:09.287843Z",
     "iopub.status.idle": "2023-01-20T01:36:09.294155Z",
     "shell.execute_reply": "2023-01-20T01:36:09.292867Z",
     "shell.execute_reply.started": "2023-01-20T01:36:09.288321Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parâmetros para extrair caminho da imagem e nome da imagem e máscara de traz para frente\n",
    "caracteres_nome_imagem = 50\n",
    "fim_imagem = 4\n",
    "fim_mask = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice\n",
    "df_imgs['caminho_imagem'].str[0:caracteres_nome_imagem][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testando\n",
    "df_imgs['caminho_imagem'].str[caracteres_nome_imagem : -fim_imagem][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testando\n",
    "df_masks['caminho_imagem'].str[caracteres_nome_imagem : -fim_mask][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T01:37:06.298913Z",
     "iopub.status.busy": "2023-01-20T01:37:06.298161Z",
     "iopub.status.idle": "2023-01-20T01:37:06.309815Z",
     "shell.execute_reply": "2023-01-20T01:37:06.308513Z",
     "shell.execute_reply.started": "2023-01-20T01:37:06.298875Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ordena imagens e máscaras obtendo os nomes de trás para frente\n",
    "imgs = sorted(df_imgs[\"caminho_imagem\"].values, key = lambda x: int(x[caracteres_nome_imagem : -fim_imagem]))\n",
    "masks = sorted(df_masks[\"caminho_imagem\"].values, key = lambda x: int(x[caracteres_nome_imagem : -fim_mask]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de imagens\n",
    "imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de máscaras\n",
    "masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T01:37:11.986156Z",
     "iopub.status.busy": "2023-01-20T01:37:11.985792Z",
     "iopub.status.idle": "2023-01-20T01:37:11.992094Z",
     "shell.execute_reply": "2023-01-20T01:37:11.991031Z",
     "shell.execute_reply.started": "2023-01-20T01:37:11.986125Z"
    }
   },
   "outputs": [],
   "source": [
    "# Verifica se o caminho foi extraído corretamente\n",
    "idx = random.randint(0, len(imgs)-1)\n",
    "print(f\"Imagem:  *{imgs[idx]}*\\nMáscara: *{masks[idx]}*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T01:37:16.905707Z",
     "iopub.status.busy": "2023-01-20T01:37:16.905327Z",
     "iopub.status.idle": "2023-01-20T01:37:16.925911Z",
     "shell.execute_reply": "2023-01-20T01:37:16.924683Z",
     "shell.execute_reply.started": "2023-01-20T01:37:16.905657Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataframe final\n",
    "df_final = pd.DataFrame({\"paciente\": df_imgs.nome_pasta.values, \"caminho_imagem\": imgs, \"caminho_mascara\": masks})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape\n",
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amostra\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T01:37:21.061215Z",
     "iopub.status.busy": "2023-01-20T01:37:21.060836Z",
     "iopub.status.idle": "2023-01-20T01:37:21.066346Z",
     "shell.execute_reply": "2023-01-20T01:37:21.065371Z",
     "shell.execute_reply.started": "2023-01-20T01:37:21.061167Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a função que aceita um caminho para uma máscara como argumento e retorna o diagnóstico\n",
    "def func_diagnostico(mask_path):\n",
    "    \n",
    "    # Carrega a máscara usando OpenCV e encontra o valor máximo de pixel na imagem\n",
    "    val = np.max(cv2.imread(mask_path))\n",
    "    \n",
    "    # Verifica se o valor máximo na imagem de máscara é maior que 0 (se for zero a máscara está vazia)\n",
    "    if val > 0: \n",
    "        return 1  # Se sim, retorna 1, indicando uma \"condição positiva\" (por exemplo, presença de área de interesse)\n",
    "    else: \n",
    "        return 0  # Se não, retorna 0, indicando uma \"condição negativa\" (por exemplo, ausência de área de interesse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T01:37:24.515066Z",
     "iopub.status.busy": "2023-01-20T01:37:24.514601Z",
     "iopub.status.idle": "2023-01-20T01:37:56.884273Z",
     "shell.execute_reply": "2023-01-20T01:37:56.883246Z",
     "shell.execute_reply.started": "2023-01-20T01:37:24.515027Z"
    }
   },
   "outputs": [],
   "source": [
    "# Aplica a função e extrai o diagnóstico\n",
    "df_final[\"diagnostico\"] = df_final[\"caminho_mascara\"].apply(lambda x: func_diagnostico(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T11:21:07.867404Z",
     "iopub.status.busy": "2023-01-19T11:21:07.866539Z",
     "iopub.status.idle": "2023-01-19T11:21:07.874553Z",
     "shell.execute_reply": "2023-01-19T11:21:07.873596Z",
     "shell.execute_reply.started": "2023-01-19T11:21:07.867356Z"
    }
   },
   "outputs": [],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T11:21:07.876984Z",
     "iopub.status.busy": "2023-01-19T11:21:07.875929Z",
     "iopub.status.idle": "2023-01-19T11:21:07.886418Z",
     "shell.execute_reply": "2023-01-19T11:21:07.885216Z",
     "shell.execute_reply.started": "2023-01-19T11:21:07.876949Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Total de Pacientes: \", len(set(df_final.paciente)))\n",
    "print(\"Total de Imagens: \", len(df_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise Exploratória e Visualização das Imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T11:21:07.888720Z",
     "iopub.status.busy": "2023-01-19T11:21:07.887683Z",
     "iopub.status.idle": "2023-01-19T11:21:08.159605Z",
     "shell.execute_reply": "2023-01-19T11:21:08.158631Z",
     "shell.execute_reply.started": "2023-01-19T11:21:07.888676Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inicia a plotagem do gráfico de barras usando os valores da coluna 'diagnostico' do DataFrame 'df_final'\n",
    "ax = df_final.diagnostico.value_counts().plot(kind = \"bar\", \n",
    "                                            stacked = True, \n",
    "                                            figsize = (12, 6), \n",
    "                                            color = [\"red\", \"green\"])\n",
    "\n",
    "# Define os rótulos do eixo X como \"Positivo\" e \"Negativo\", com rotação de 45 graus e tamanho de fonte 12\n",
    "ax.set_xticklabels([\"Positivo\", \"Negativo\"], rotation = 45, fontsize = 12)\n",
    "\n",
    "# Define o rótulo do eixo Y como \"Total Imagens\" com tamanho de fonte 12\n",
    "ax.set_ylabel(\"Total Images\", fontsize = 12)\n",
    "\n",
    "# Define o título do gráfico, o tamanho da fonte do título e a posição vertical do título\n",
    "ax.set_title(\"Proporção de Registros Por Diagnóstico\", fontsize = 18, y = 1.05)\n",
    "\n",
    "# Loop para anotar cada barra do gráfico com o número total de ocorrências para cada diagnóstico\n",
    "for i, rows in enumerate(df_final.diagnostico.value_counts().values):\n",
    "    ax.annotate(int(rows), \n",
    "                xy = (i, rows-12), \n",
    "                rotation = 0, \n",
    "                color = \"white\", \n",
    "                ha = \"center\", \n",
    "                verticalalignment = 'bottom', \n",
    "                fontsize = 15, \n",
    "                fontweight = \"bold\")\n",
    "    \n",
    "# Adiciona um texto ao gráfico indicando o número total de imagens\n",
    "ax.text(1.2, 2550, f\"Total de {len(df_final)} Imagens\", \n",
    "        size = 15,\n",
    "        color = \"black\",\n",
    "        ha = \"center\", \n",
    "        va = \"center\",\n",
    "        bbox = dict(boxstyle = \"round\", fc = (\"lightblue\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T11:21:08.161768Z",
     "iopub.status.busy": "2023-01-19T11:21:08.160925Z",
     "iopub.status.idle": "2023-01-19T11:21:08.175913Z",
     "shell.execute_reply": "2023-01-19T11:21:08.174869Z",
     "shell.execute_reply.started": "2023-01-19T11:21:08.161727Z"
    }
   },
   "outputs": [],
   "source": [
    "# Retorna quantas imagens diagnosticadas e não diagnosticadas cada paciente possui\n",
    "df_final.groupby([\"paciente\", \"diagnostico\"])[\"diagnostico\"].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T11:21:08.178042Z",
     "iopub.status.busy": "2023-01-19T11:21:08.177645Z",
     "iopub.status.idle": "2023-01-19T11:21:08.196837Z",
     "shell.execute_reply": "2023-01-19T11:21:08.195810Z",
     "shell.execute_reply.started": "2023-01-19T11:21:08.178005Z"
    }
   },
   "outputs": [],
   "source": [
    "# Agrupa pacientes por diagnóstico e preenche valores NA\n",
    "pacientes_por_diagnostico = df_final.groupby([\"paciente\", \"diagnostico\"])[\"diagnostico\"].size().unstack().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajusta os nomes das colunas\n",
    "pacientes_por_diagnostico.columns = [\"Positivo\", \"Negativo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza as primeiras linhas\n",
    "pacientes_por_diagnostico.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T11:21:08.198763Z",
     "iopub.status.busy": "2023-01-19T11:21:08.198372Z",
     "iopub.status.idle": "2023-01-19T11:21:10.598927Z",
     "shell.execute_reply": "2023-01-19T11:21:10.597968Z",
     "shell.execute_reply.started": "2023-01-19T11:21:08.198725Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "ax = pacientes_por_diagnostico.plot(kind = \"bar\", \n",
    "                                    stacked = True, \n",
    "                                    figsize = (18,10), \n",
    "                                    color = [\"blue\", \"magenta\"], \n",
    "                                    alpha = 0.85)\n",
    "ax.grid(False)\n",
    "ax.set_xlabel('Pacientes',fontsize = 20)\n",
    "ax.set_ylabel('Total de Imagens', fontsize = 20)\n",
    "ax.legend(fontsize = 20, loc = \"upper left\")\n",
    "ax.set_title(\"Distribuição dos Dados Agrupados Por Paciente e Diagnóstico\", fontsize = 25, y = 1.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Vamos agora visualizar imagens e máscaras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa amostras com diagnóstico positivo e negativo\n",
    "sample_pos = df_final[df_final[\"diagnostico\"] == 1].sample(5).caminho_imagem.values\n",
    "sample_neg = df_final[df_final[\"diagnostico\"] == 0].sample(5).caminho_imagem.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para as amostras de imagens\n",
    "sample_imgs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamanho de cada imagem\n",
    "IMG_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T11:21:10.600341Z",
     "iopub.status.busy": "2023-01-19T11:21:10.599953Z",
     "iopub.status.idle": "2023-01-19T11:21:10.736788Z",
     "shell.execute_reply": "2023-01-19T11:21:10.735742Z",
     "shell.execute_reply.started": "2023-01-19T11:21:10.600305Z"
    }
   },
   "outputs": [],
   "source": [
    "# Carrega as imagens e separa pelo diagnóstico\n",
    "for i, (pos, neg) in enumerate(zip(sample_pos, sample_neg)):\n",
    "    pos = cv2.resize(cv2.imread(pos), (IMG_SIZE, IMG_SIZE))\n",
    "    neg = cv2.resize(cv2.imread(neg), (IMG_SIZE, IMG_SIZE))\n",
    "    sample_imgs.extend([pos, neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte as amostras para array \n",
    "sample_yes_arr = np.vstack(np.array(sample_imgs[::2]))\n",
    "sample_no_arr = np.vstack(np.array(sample_imgs[1::2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T11:21:10.739652Z",
     "iopub.status.busy": "2023-01-19T11:21:10.739063Z",
     "iopub.status.idle": "2023-01-19T11:21:10.746659Z",
     "shell.execute_reply": "2023-01-19T11:21:10.745606Z",
     "shell.execute_reply.started": "2023-01-19T11:21:10.739615Z"
    }
   },
   "outputs": [],
   "source": [
    "# Matriz de 2560 imagens, com 512 pixels de tamanho e 3 canais de cores\n",
    "sample_yes_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Máscaras\n",
    "sample_df = df_final[df_final[\"diagnostico\"] == 1].sample(5).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_imgs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T11:21:15.211821Z",
     "iopub.status.busy": "2023-01-19T11:21:15.211169Z",
     "iopub.status.idle": "2023-01-19T11:21:15.343176Z",
     "shell.execute_reply": "2023-01-19T11:21:15.342150Z",
     "shell.execute_reply.started": "2023-01-19T11:21:15.211784Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loop para buscar imagens e máscaras na amostra\n",
    "for i, data in enumerate(sample_df):\n",
    "    img = cv2.resize(cv2.imread(data[1]), (IMG_SIZE, IMG_SIZE))\n",
    "    mask = cv2.resize(cv2.imread(data[2]), (IMG_SIZE, IMG_SIZE))\n",
    "    sample_imgs.extend([img, mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T11:21:15.345161Z",
     "iopub.status.busy": "2023-01-19T11:21:15.344519Z",
     "iopub.status.idle": "2023-01-19T11:21:15.352690Z",
     "shell.execute_reply": "2023-01-19T11:21:15.351830Z",
     "shell.execute_reply.started": "2023-01-19T11:21:15.345124Z"
    }
   },
   "outputs": [],
   "source": [
    "# Converte para array\n",
    "sample_img_arr = np.hstack(sample_imgs[::2])\n",
    "sample_mask_arr = np.hstack(sample_imgs[1::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T11:21:15.355376Z",
     "iopub.status.busy": "2023-01-19T11:21:15.354607Z",
     "iopub.status.idle": "2023-01-19T11:21:16.373679Z",
     "shell.execute_reply": "2023-01-19T11:21:16.372094Z",
     "shell.execute_reply.started": "2023-01-19T11:21:15.355325Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig = plt.figure(figsize = (25., 25.))\n",
    "grid = ImageGrid(fig, 111,  nrows_ncols = (2, 1), axes_pad = 0.1)\n",
    "grid[0].imshow(sample_img_arr)\n",
    "grid[0].set_title(\"Imagens\", fontsize = 25)\n",
    "grid[0].axis(\"off\")\n",
    "grid[0].grid(False)\n",
    "grid[1].imshow(sample_mask_arr)\n",
    "grid[1].set_title(\"Máscaras\", fontsize = 25, y = 0.9)\n",
    "grid[1].axis(\"off\")\n",
    "grid[1].grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Augmentation e DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T01:39:33.789429Z",
     "iopub.status.busy": "2023-01-20T01:39:33.787949Z",
     "iopub.status.idle": "2023-01-20T01:39:33.906450Z",
     "shell.execute_reply": "2023-01-20T01:39:33.904817Z",
     "shell.execute_reply.started": "2023-01-20T01:39:33.789383Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se CUDA estiver instalado, verifica a GPU\n",
    "if torch.cuda.is_available():\n",
    "    print('Número de GPUs:', torch.cuda.device_count())\n",
    "    print('Modelo da GPU:',torch.cuda.get_device_name(0))\n",
    "    print('Total de Memória da GPU [GB]:',torch.cuda.get_device_properties(0).total_memory/1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T02:01:24.075153Z",
     "iopub.status.busy": "2023-01-20T02:01:24.074113Z",
     "iopub.status.idle": "2023-01-20T02:01:24.083703Z",
     "shell.execute_reply": "2023-01-20T02:01:24.082076Z",
     "shell.execute_reply.started": "2023-01-20T02:01:24.075115Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a classe para criar o dataset\n",
    "class PreparaDataset:\n",
    "    \n",
    "    # Método construtor para inicializar os atributos da classe\n",
    "    def __init__(self, df, transforms):\n",
    "        \n",
    "        # DataFrame contendo informações sobre as imagens e máscaras\n",
    "        self.df = df  \n",
    "        \n",
    "        # Transformações a serem aplicadas nas imagens e máscaras\n",
    "        self.transforms = transforms  \n",
    "\n",
    "    # Método para obter um item específico do conjunto de dados usando um índice\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # Lê a imagem da localização especificada na coluna 1 do DataFrame\n",
    "        image = cv2.imread(self.df.iloc[idx, 1])\n",
    "        \n",
    "        # Lê a máscara da localização especificada na coluna 2 do DataFrame\n",
    "        # '0' indica que a imagem é lida em escala de cinza\n",
    "        mask = cv2.imread(self.df.iloc[idx, 2], 0)\n",
    "        \n",
    "        # Aplica as transformações especificadas em 'self.transforms' tanto na imagem quanto na máscara\n",
    "        augmented = self.transforms(image = image, mask = mask)\n",
    "        \n",
    "        # Atualiza a imagem e a máscara com as versões transformadas\n",
    "        image = augmented[\"image\"]\n",
    "        mask = augmented[\"mask\"]\n",
    "        \n",
    "        # Retorna a imagem e a máscara como uma tupla\n",
    "        return image, mask\n",
    "\n",
    "    # Método para obter o número total de itens no conjunto de dados\n",
    "    def __len__(self):\n",
    "        \n",
    "        # Retorna o número de linhas no DataFrame\n",
    "        return len(self.df)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamanho do patch\n",
    "PATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui definimos uma sequência de transformações a serem aplicadas nas imagens\n",
    "transforms = A.Compose([\n",
    "    \n",
    "    # Redimensiona a imagem para o tamanho especificado (PATCH_SIZE x PATCH_SIZE)\n",
    "    A.Resize(width = PATCH_SIZE, height = PATCH_SIZE, p = 1.0),\n",
    "    \n",
    "    # Espelha a imagem horizontalmente com probabilidade de 0,5\n",
    "    A.HorizontalFlip(p = 0.5),\n",
    "    \n",
    "    # Espelha a imagem verticalmente com probabilidade de 0,5\n",
    "    A.VerticalFlip(p = 0.5),\n",
    "    \n",
    "    # Gira a imagem aleatoriamente em 90 graus com probabilidade de 0,5\n",
    "    A.RandomRotate90(p = 0.5),\n",
    "    \n",
    "    # Transpõe a imagem (inverte altura e largura) com probabilidade de 0,5\n",
    "    A.Transpose(p = 0.5),\n",
    "    \n",
    "    # Realiza pequenos deslocamentos, redimensionamentos e rotações na imagem com probabilidade de 0,25\n",
    "    A.ShiftScaleRotate(shift_limit = 0.01, scale_limit = 0.04, rotate_limit = 0, p = 0.25),\n",
    "\n",
    "    # Normaliza a imagem para ter uma média de 0 e um desvio padrão de 1\n",
    "    A.Normalize(p = 1.0),\n",
    "    \n",
    "    # Converte a imagem para um tensor do PyTorch\n",
    "    ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria amostra de treino e validação\n",
    "df_treino, df_valid = train_test_split(df_final, stratify = df_final.diagnostico, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset do índice\n",
    "df_treino = df_treino.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset do índice\n",
    "df_valid = df_valid.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide dados de treino em treino e teste\n",
    "df_treino, df_teste = train_test_split(df_treino, stratify = df_treino.diagnostico, test_size = 0.12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset do índice\n",
    "df_treino = df_treino.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T02:01:31.652837Z",
     "iopub.status.busy": "2023-01-20T02:01:31.652105Z",
     "iopub.status.idle": "2023-01-20T02:01:31.668517Z",
     "shell.execute_reply": "2023-01-20T02:01:31.667126Z",
     "shell.execute_reply.started": "2023-01-20T02:01:31.652798Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Treino: {df_treino.shape} \\nValid: {df_valid.shape} \\nTeste: {df_teste.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica as transformações em treino\n",
    "dataset_treino = PreparaDataset(df_treino, transforms = transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dataset_treino))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o dataloader de treino\n",
    "dl_treino = DataLoader(dataset_treino, batch_size = 26, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica as transformações em validação\n",
    "dataset_valid = PreparaDataset(df_valid, transforms = transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dataset_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o dataloader de validação\n",
    "dl_valid = DataLoader(dataset_valid, batch_size = 26, num_workers = 2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T02:01:33.809754Z",
     "iopub.status.busy": "2023-01-20T02:01:33.808929Z",
     "iopub.status.idle": "2023-01-20T02:01:33.816564Z",
     "shell.execute_reply": "2023-01-20T02:01:33.815414Z",
     "shell.execute_reply.started": "2023-01-20T02:01:33.809704Z"
    }
   },
   "outputs": [],
   "source": [
    "# Aplica as transformações em teste\n",
    "dataset_teste = PreparaDataset(df_teste, transforms = transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T01:44:53.802364Z",
     "iopub.status.busy": "2023-01-20T01:44:53.801905Z",
     "iopub.status.idle": "2023-01-20T01:44:53.813208Z",
     "shell.execute_reply": "2023-01-20T01:44:53.812019Z",
     "shell.execute_reply.started": "2023-01-20T01:44:53.802326Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(dataset_teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o dataloader de teste\n",
    "dl_teste = DataLoader(dataset_teste, batch_size = 26, num_workers = 2, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Vamos definir a função para exibir imagens após a aplicação das transformações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T02:01:36.600857Z",
     "iopub.status.busy": "2023-01-20T02:01:36.600023Z",
     "iopub.status.idle": "2023-01-20T02:01:36.610652Z",
     "shell.execute_reply": "2023-01-20T02:01:36.609290Z",
     "shell.execute_reply.started": "2023-01-20T02:01:36.600820Z"
    }
   },
   "outputs": [],
   "source": [
    "# Função\n",
    "def mostra_imagens(inputs, nrows = 5, ncols = 5, norm = True):\n",
    "    \n",
    "    # Cria uma figura para o plot das imagens\n",
    "    plt.figure(figsize = (10, 10))\n",
    "    \n",
    "    # Ajusta o espaço entre subplots\n",
    "    plt.subplots_adjust(wspace = 0., hspace = 0.)\n",
    "    \n",
    "    # Inicializa o contador para subplots\n",
    "    i_ = 0\n",
    "    \n",
    "    # Limita o número de entradas para no máximo 25\n",
    "    if len(inputs) > 25:\n",
    "        inputs = inputs[:25]\n",
    "    \n",
    "    # Loop para iterar através de todas as imagens na lista de entrada\n",
    "    for idx in range(len(inputs)):\n",
    "        \n",
    "        # Normaliza as imagens se 'norm' for True\n",
    "        if norm:\n",
    "            \n",
    "            # Transpõe a imagem e converte para o formato NumPy\n",
    "            img = inputs[idx].numpy().transpose(1, 2, 0)\n",
    "            \n",
    "            # Define a média e o desvio padrão para normalização\n",
    "            mean = [0.485, 0.456, 0.406]\n",
    "            std = [0.229, 0.224, 0.225]\n",
    "            \n",
    "            # Desnormaliza a imagem\n",
    "            img = (img * std + mean).astype(np.float32)\n",
    "        \n",
    "        # Caso contrário, apenas converte para o formato NumPy sem normalização\n",
    "        else:\n",
    "            img = inputs[idx].numpy().astype(np.float32)\n",
    "            img = img[0, :, :]\n",
    "        \n",
    "        # Adiciona um subplot na posição i_ + 1\n",
    "        plt.subplot(nrows, ncols, i_ + 1)\n",
    "        \n",
    "        # Plota a imagem em escala de cinza se ela tiver menos de 3 dimensões\n",
    "        if len(img.shape) < 3:\n",
    "            plt.imshow(img, cmap = \"gray\")\n",
    "        \n",
    "        # Caso contrário, plota a imagem colorida\n",
    "        else:\n",
    "            plt.imshow(img)\n",
    "        \n",
    "        # Remove os eixos do subplot\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Incrementa o contador de subplots\n",
    "        i_ += 1\n",
    "    \n",
    "    # Exibe a figura com todos os subplots\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica se o script está sendo executado como o programa principal\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # Obtém o próximo lote de imagens e máscaras do dataloader de treinamento\n",
    "    images, masks = next(iter(dl_treino))\n",
    "    \n",
    "    # Exibe as dimensões das matrizes de imagens e máscaras\n",
    "    print(images.shape, masks.shape)\n",
    "    \n",
    "    # Usa a função 'mostra_imagens' para exibir as imagens\n",
    "    # Aqui, a normalização é assumida como verdadeira por padrão\n",
    "    mostra_imagens(images)\n",
    "    \n",
    "    # Usa a função 'mostra_imagens' para exibir as máscaras\n",
    "    # Neste caso, 'norm' é definido como falso para evitar a normalização\n",
    "    mostra_imagens(masks, norm = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelagem Para Segmentação de Imagens com Arquitetura U-Net\n",
    "\n",
    "A arquitetura U-Net é um tipo de rede neural convolucional que foi inicialmente projetada para tarefas de segmentação semântica em imagens biomédicas. A estrutura foi apresentada por Olaf Ronneberger, Philipp Fischer e Thomas Brox em 2015, e desde então tem sido adaptada e utilizada em várias outras tarefas de segmentação e análise de imagens. Link do paper de pesquisa:\n",
    "\n",
    "https://arxiv.org/abs/1505.04597\n",
    "\n",
    "**Estrutura Básica**\n",
    "\n",
    "A U-Net tem uma estrutura simétrica que se assemelha a um \"U\", razão pela qual é chamada de U-Net. A rede é composta por duas partes principais:\n",
    "\n",
    "Codificador (Downsampling Path): A primeira metade da rede consiste em várias camadas convolucionais e camadas de pooling para reduzir as dimensões espaciais da imagem de entrada. Isso permite que a rede capture as características contextuais da imagem. Geralmente, cada etapa de downsampling é composta por duas convoluções seguidas por uma operação de pooling (geralmente max pooling).\n",
    "\n",
    "Decodificador (Upsampling Path): A segunda metade da rede faz o oposto do codificador. Ela recebe a saída do codificador e aumenta suas dimensões espaciais usando camadas de convolução transposta (ou upsampling). Para capturar informações de localização com precisão, as saídas de algumas das camadas do codificador são concatenadas com as entradas das camadas correspondentes no decodificador.\n",
    "\n",
    "**Características Importantes**\n",
    "\n",
    "Skip Connections: Uma característica marcante da U-Net é o uso de conexões de salto (skip connections) entre as camadas do codificador e do decodificador. Isso permite que a rede preserve informações de localização, que são fundamentais para tarefas como segmentação de imagem.\n",
    "\n",
    "Camadas Totalmente Conectadas: Diferentemente de outras redes neurais convolucionais, a U-Net geralmente não contém camadas totalmente conectadas, o que a torna mais eficiente em termos de uso de memória.\n",
    "\n",
    "Campo Receptivo Grande: Devido às múltiplas camadas de downsampling e upsampling, a U-Net possui um campo receptivo grande, permitindo que capture mais contexto em torno de cada pixel.\n",
    "\n",
    "Treinamento com Poucos Dados: Uma das principais vantagens da U-Net é sua eficácia mesmo quando treinada com uma quantidade relativamente pequena de dados anotados.\n",
    "\n",
    "**Aplicações**\n",
    "\n",
    "Embora inicialmente projetada para imagens biomédicas, a arquitetura U-Net foi adotada em diversas áreas, como detecção de objetos, visão robótica, análise de imagens médicas não biomédicas e até mesmo em processamento de linguagem natural.\n",
    "\n",
    "Referência:\n",
    "\n",
    "https://arxiv.org/abs/1505.04597"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DSA](imagens/unet.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T11:21:36.117937Z",
     "iopub.status.busy": "2023-01-19T11:21:36.117599Z",
     "iopub.status.idle": "2023-01-19T11:21:36.123364Z",
     "shell.execute_reply": "2023-01-19T11:21:36.122043Z",
     "shell.execute_reply.started": "2023-01-19T11:21:36.117909Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define uma função para criar uma operação de convolução dupla\n",
    "def double_conv(in_channels, out_channels):\n",
    "    \n",
    "    # Retorna uma sequência de operações em uma rede neural (nn.Sequential)\n",
    "    return nn.Sequential(\n",
    "        \n",
    "        # Primeira convolução: recebe 'in_channels' e retorna 'out_channels'\n",
    "        # O kernel é de tamanho 3x3 e o padding é 1 para manter as dimensões\n",
    "        nn.Conv2d(in_channels, out_channels, 3, padding = 1),\n",
    "        \n",
    "        # Aplica a função de ativação ReLU in-place após a primeira convolução\n",
    "        nn.ReLU(inplace = True),\n",
    "        \n",
    "        # Segunda convolução: recebe 'out_channels' (saída da primeira convolução) e também retorna 'out_channels'\n",
    "        # O kernel é de tamanho 3x3 e o padding é 1 para manter as dimensões\n",
    "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "        \n",
    "        # Aplica a função de ativação ReLU in-place após a segunda convolução\n",
    "        nn.ReLU(inplace = True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T11:21:36.125422Z",
     "iopub.status.busy": "2023-01-19T11:21:36.124828Z",
     "iopub.status.idle": "2023-01-19T11:21:36.137999Z",
     "shell.execute_reply": "2023-01-19T11:21:36.136978Z",
     "shell.execute_reply.started": "2023-01-19T11:21:36.125385Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a classe UNet, herdando de nn.Module (PyTorch)\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    # Construtor da classe\n",
    "    def __init__(self, n_classes):\n",
    "        \n",
    "        # Chama o construtor da classe pai (nn.Module)\n",
    "        super().__init__()\n",
    "                \n",
    "        # Camadas de convolução descendentes (Encoder)\n",
    "        self.conv_down1 = double_conv(3, 64)\n",
    "        self.conv_down2 = double_conv(64, 128)\n",
    "        self.conv_down3 = double_conv(128, 256)\n",
    "        self.conv_down4 = double_conv(256, 512)\n",
    "        \n",
    "        # Camada de Max pooling para reduzir dimensões\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        \n",
    "        # Camada de Upsample para aumentar dimensões (Decoder)\n",
    "        self.upsample = nn.Upsample(scale_factor = 2, mode = 'bilinear', align_corners = True)\n",
    "        \n",
    "        # Camadas de convolução ascendentes (Decoder)\n",
    "        self.conv_up3 = double_conv(256 + 512, 256)\n",
    "        self.conv_up2 = double_conv(128 + 256, 128)\n",
    "        self.conv_up1 = double_conv(128 + 64, 64)\n",
    "        \n",
    "        # Última camada de convolução para ajustar o número de classes\n",
    "        self.last_conv = nn.Conv2d(64, n_classes, kernel_size = 1)\n",
    "\n",
    "    # Método para a passagem para a frente (forward pass)\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Convoluções descendentes e Max pooling\n",
    "        conv1 = self.conv_down1(x)\n",
    "        x = self.maxpool(conv1)\n",
    "        \n",
    "        conv2 = self.conv_down2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "        \n",
    "        conv3 = self.conv_down3(x)\n",
    "        x = self.maxpool(conv3)\n",
    "        \n",
    "        # Última convolução descendente\n",
    "        x = self.conv_down4(x)\n",
    "        \n",
    "        # Inicia o processo de upsampling (decodificação)\n",
    "        x = self.upsample(x)\n",
    "        \n",
    "        # Concatenação e convolução ascendente\n",
    "        x = torch.cat([x, conv3], dim = 1)\n",
    "        x = self.conv_up3(x)\n",
    "        \n",
    "        x = self.upsample(x)\n",
    "        \n",
    "        x = torch.cat([x, conv2], dim = 1)\n",
    "        x = self.conv_up2(x)\n",
    "        \n",
    "        x = self.upsample(x)\n",
    "        \n",
    "        x = torch.cat([x, conv1], dim = 1)\n",
    "        x = self.conv_up1(x)\n",
    "        \n",
    "        # Última camada de convolução e ativação\n",
    "        out = self.last_conv(x)\n",
    "        \n",
    "        # Aplica a função de ativação sigmóide para normalizar a saída\n",
    "        out = torch.sigmoid(out)\n",
    "        \n",
    "        # Retorna a saída\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T11:21:36.139759Z",
     "iopub.status.busy": "2023-01-19T11:21:36.139414Z",
     "iopub.status.idle": "2023-01-19T11:21:39.649246Z",
     "shell.execute_reply": "2023-01-19T11:21:39.648216Z",
     "shell.execute_reply.started": "2023-01-19T11:21:36.139724Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cria instância da classe e manda para o device\n",
    "modelo_unet_padrao = UNet(n_classes = 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arquitetura final\n",
    "modelo_unet_padrao.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas de Avaliação Para Segmentação de Imagens\n",
    "\n",
    "O Coeficiente de Dice é uma métrica estatística utilizada para avaliar a semelhança entre dois conjuntos. O coeficiente é amplamente usado em diversas áreas, incluindo ecologia, informática e, mais notavelmente, em processamento de imagem e aprendizado de máquina para tarefas como segmentação de imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T11:21:51.160019Z",
     "iopub.status.busy": "2023-01-19T11:21:51.159142Z",
     "iopub.status.idle": "2023-01-19T11:21:51.166684Z",
     "shell.execute_reply": "2023-01-19T11:21:51.165636Z",
     "shell.execute_reply.started": "2023-01-19T11:21:51.159980Z"
    }
   },
   "outputs": [],
   "source": [
    "# Função para métrica de segmentação\n",
    "def dice_coef_metric(inputs, target):\n",
    "    \n",
    "    # Calcula a interseção entre o alvo (target) e as entradas (inputs), multiplicando-os \n",
    "    # elemento a elemento e somando o resultado.\n",
    "    # Multiplica por 2.0 para seguir a fórmula do coeficiente de Dice.\n",
    "    intersection = 2.0 * (target * inputs).sum()\n",
    "\n",
    "    # Calcula a união entre o alvo e as entradas, somando todos os elementos de cada um.\n",
    "    union = target.sum() + inputs.sum()\n",
    "\n",
    "    # Verifica se tanto o alvo quanto as entradas são vetores de zeros.\n",
    "    # Se forem, o coeficiente de Dice é definido como 1.0 nesse caso.\n",
    "    if target.sum() == 0 and inputs.sum() == 0:\n",
    "        return 1.0\n",
    "    \n",
    "    # Calcula e retorna o coeficiente de Dice usando a fórmula: 2 * |X ∩ Y| / (|X| + |Y|)\n",
    "    return intersection / union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função dice_coef_loss abaixo é uma versão modificada do coeficiente de Dice, adaptada para ser usada como uma função de perda em algoritmos de aprendizado de máquina. A ideia é minimizar essa perda durante o treinamento para que a rede neural gere segmentações que são o mais próximo possível dos rótulos verdadeiros.\n",
    "\n",
    "A adição do termo smooth é uma técnica comum para evitar divisão por zero e para suavizar o gradiente, tornando o treinamento mais estável. O termo é adicionado tanto no numerador quanto no denominador da fração para manter a simetria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para o erro de segmentação\n",
    "def dice_coef_loss(inputs, target):\n",
    "    \n",
    "    # Adiciona um valor suavizador (\"smooth\") para evitar divisão por zero\n",
    "    smooth = 1.0 \n",
    "\n",
    "    # Calcula a interseção entre a entrada e o alvo, multiplicando-os elemento a elemento e somando o resultado.\n",
    "    # Multiplica por 2.0 para seguir a fórmula do coeficiente de Dice.\n",
    "    # Adiciona o valor de \"smooth\" para suavização.\n",
    "    intersection = 2.0 * (target * inputs).sum() + smooth\n",
    "\n",
    "    # Calcula a união entre o alvo e as entradas, somando todos os elementos de cada um.\n",
    "    # Adiciona o valor de \"smooth\" para suavização.\n",
    "    union = target.sum() + inputs.sum() + smooth\n",
    "\n",
    "    # Calcula a perda como 1 menos o coeficiente de Dice.\n",
    "    # O objetivo durante o treinamento é minimizar essa perda, o que maximiza o coeficiente de Dice.\n",
    "    return 1 - (intersection / union)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função bce_dice_loss abaixo combina duas métricas de perda comuns em tarefas de segmentação de imagem: a perda de coeficiente de Dice e a perda de entropia cruzada binária (BCE, do inglês \"Binary Cross Entropy\").\n",
    "\n",
    "**Dice Loss**: dice_coef_loss(inputs, target) computa a perda baseada no coeficiente de Dice, que é útil para medir a similaridade entre a saída prevista (inputs) e a verdadeira (target).\n",
    "\n",
    "**BCE Loss**: nn.BCELoss() inicializa a perda de entropia cruzada binária, que é comumente usada para problemas de classificação binária. A função bce_loss(inputs, target) então calcula esta perda entre as entradas e os alvos.\n",
    "\n",
    "**Combinação**: O valor retornado é a soma das duas perdas. Isso é feito para aproveitar os benefícios de ambas as métricas: enquanto a BCE é eficaz para a classificação pixel a pixel, o coeficiente de Dice leva em consideração a relação espacial entre os pixels.\n",
    "\n",
    "Esta abordagem combinada é frequentemente mais robusta do que usar qualquer uma das métricas isoladamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para o erro final de segmentação\n",
    "def bce_dice_loss(inputs, target):\n",
    "    \n",
    "    # Calcula o valor da função de perda baseada no coeficiente de Dice\n",
    "    dice_score = dice_coef_loss(inputs, target)\n",
    "    \n",
    "    # Inicializa a função de perda de entropia cruzada binária (BCE)\n",
    "    bce_loss = nn.BCELoss()\n",
    "    \n",
    "    # Calcula o valor da função de perda de entropia cruzada binária para as entradas e alvos dados\n",
    "    bce_score = bce_loss(inputs, target)\n",
    "    \n",
    "    # Soma as duas funções de perda (Dice e BCE) para obter uma métrica de perda combinada\n",
    "    return bce_score + dice_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T11:21:51.181026Z",
     "iopub.status.busy": "2023-01-19T11:21:51.180748Z",
     "iopub.status.idle": "2023-01-19T11:21:51.197941Z",
     "shell.execute_reply": "2023-01-19T11:21:51.196795Z",
     "shell.execute_reply.started": "2023-01-19T11:21:51.181001Z"
    }
   },
   "outputs": [],
   "source": [
    "# Testando\n",
    "bce_dice_loss(torch.tensor([0.7, 1., 1.]), torch.tensor([1.,1.,1.]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop de Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "\n",
    "Leia o manual em pdf no Capítulo 14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T11:21:51.200087Z",
     "iopub.status.busy": "2023-01-19T11:21:51.199531Z",
     "iopub.status.idle": "2023-01-19T11:21:51.206661Z",
     "shell.execute_reply": "2023-01-19T11:21:51.205584Z",
     "shell.execute_reply.started": "2023-01-19T11:21:51.200052Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a classe EarlyStopping para interromper o treinamento quando não houver melhora\n",
    "class EarlyStopping():\n",
    "\n",
    "    # Inicializa a classe com parâmetros de tolerância e variação mínima (min_delta)\n",
    "    def __init__(self, tolerance = 4, min_delta = 0):\n",
    "        \n",
    "        # Número máximo de épocas para tolerar sem melhora\n",
    "        self.tolerance = tolerance  \n",
    "        \n",
    "        # A diferença mínima entre a perda de treino e validação para considerar como melhora\n",
    "        self.min_delta = min_delta  \n",
    "        \n",
    "        # Contador para rastrear o número de épocas sem melhora\n",
    "        self.counter = 0  \n",
    "        \n",
    "        # Sinalizador para indicar se o treinamento deve ser interrompido\n",
    "        self.early_stop = False  \n",
    "\n",
    "    # Método chamado em cada época para verificar as condições de parada antecipada\n",
    "    def __call__(self, train_loss, validation_loss):\n",
    "        \n",
    "        # Verifica se a diferença entre a perda de validação e a perda de treino é maior que min_delta\n",
    "        if (validation_loss - train_loss) > self.min_delta:\n",
    "            \n",
    "            # Incrementa o contador se a condição for atendida\n",
    "            self.counter += 1  \n",
    "            \n",
    "            # Verifica se o contador atingiu o limite de tolerância\n",
    "            if self.counter >= self.tolerance:\n",
    "                \n",
    "                # Ativa o sinalizador para interromper o treinamento\n",
    "                self.early_stop = True  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T11:21:51.208872Z",
     "iopub.status.busy": "2023-01-19T11:21:51.208109Z",
     "iopub.status.idle": "2023-01-19T11:21:51.217131Z",
     "shell.execute_reply": "2023-01-19T11:21:51.216106Z",
     "shell.execute_reply.started": "2023-01-19T11:21:51.208834Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cria instância da classe\n",
    "early_stopping = EarlyStopping(tolerance = 4, min_delta = 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função Para Calcular o IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T11:21:51.235784Z",
     "iopub.status.busy": "2023-01-19T11:21:51.235388Z",
     "iopub.status.idle": "2023-01-19T11:21:51.249373Z",
     "shell.execute_reply": "2023-01-19T11:21:51.248356Z",
     "shell.execute_reply.started": "2023-01-19T11:21:51.235747Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define uma função para calcular a métrica IOU (Intersection Over Union) usando um modelo e um DataLoader\n",
    "def compute_iou(model, loader, threshold = 0.3):\n",
    "    \n",
    "    # Inicializa a variável de perda de validação\n",
    "    valloss = 0\n",
    "    \n",
    "    # Desativa o cálculo de gradientes para economizar memória e acelerar os cálculos\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # Itera sobre o DataLoader, obtendo batches de dados e seus respectivos rótulos (target)\n",
    "        for i_step, (data, target) in enumerate(loader):\n",
    "            \n",
    "            # Move o tensor de dados para a GPU ou outro dispositivo especificado\n",
    "            data = data.to(device)\n",
    "            \n",
    "            # Move o tensor de rótulos (target) para a GPU ou outro dispositivo especificado\n",
    "            target = target.to(device)\n",
    "            \n",
    "            # Utiliza o modelo para gerar previsões\n",
    "            outputs = model(data)\n",
    "\n",
    "            # Copia as saídas para a CPU e converte para um array NumPy, desanexando do gráfico de computação\n",
    "            out_cut = np.copy(outputs.data.cpu().detach())\n",
    "            \n",
    "            # Aplica um limiar para definir os pixels como pertencentes à classe de interesse ou não\n",
    "            out_cut[np.nonzero(out_cut < threshold)] = 0.0\n",
    "            \n",
    "            # Aplica um limiar para definir os pixels como pertencentes à classe de interesse ou não\n",
    "            out_cut[np.nonzero(out_cut >= threshold)] = 1.0\n",
    "\n",
    "            # Calcula a métrica de perda usando coeficiente de Dice \n",
    "            picloss = dice_coef_metric(out_cut, target.data.cpu().numpy())\n",
    "            \n",
    "            # Acumula as perdas para posterior média\n",
    "            valloss += picloss\n",
    "\n",
    "    # Retorna a média da perda de validação\n",
    "    return valloss / i_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função Para Ajustar a Taxa de Aprendizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T11:21:51.251457Z",
     "iopub.status.busy": "2023-01-19T11:21:51.251013Z",
     "iopub.status.idle": "2023-01-19T11:21:51.259747Z",
     "shell.execute_reply": "2023-01-19T11:21:51.258725Z",
     "shell.execute_reply.started": "2023-01-19T11:21:51.251420Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a função warmup_lr_scheduler para ajustar a taxa de aprendizado durante as iterações iniciais\n",
    "def warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor):\n",
    "    \n",
    "    # Define a função f(x) que modifica a taxa de aprendizado com base na iteração atual x\n",
    "    def f(x):\n",
    "        \n",
    "        # Se a iteração atual for maior ou igual ao número de iterações de aquecimento, retorna 1\n",
    "        # Isso significa que após warmup_iters iterações, a taxa de aprendizado não será mais ajustada\n",
    "        if x >= warmup_iters:\n",
    "            return 1\n",
    "        \n",
    "        # Calcula o fator alpha como a razão da iteração atual para as iterações de aquecimento totais\n",
    "        alpha = float(x) / warmup_iters\n",
    "        \n",
    "        # Calcula o valor da taxa de aprendizado usando o fator de aquecimento e alpha\n",
    "        # Durante o aquecimento, este valor será menor que 1, escalando a taxa de aprendizado original\n",
    "        return warmup_factor * (1 - alpha) + alpha\n",
    "\n",
    "    # Retorna um agendador de taxa de aprendizado que ajusta a taxa de aprendizado do otimizador usando f(x)\n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T11:21:51.219314Z",
     "iopub.status.busy": "2023-01-19T11:21:51.218848Z",
     "iopub.status.idle": "2023-01-19T11:21:51.233726Z",
     "shell.execute_reply": "2023-01-19T11:21:51.232690Z",
     "shell.execute_reply.started": "2023-01-19T11:21:51.219277Z"
    }
   },
   "outputs": [],
   "source": [
    "# Função para treinar um modelo\n",
    "def treina_modelo(model_name, model, train_loader, val_loader, train_loss, optimizer, lr_scheduler, num_epochs):\n",
    "    \n",
    "    # Mostra uma mensagem informando que o treinamento foi iniciado\n",
    "    print(f\"Iniciando o Treinamento do Modelo {model_name}\")\n",
    "    \n",
    "    # Listas para armazenar histórico de perda e métricas\n",
    "    loss_history = []\n",
    "    train_history = []\n",
    "    val_history = []\n",
    "        \n",
    "    # Loop sobre o número total de épocas\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # Configura o modelo para o modo de treinamento\n",
    "        model.train()\n",
    "        \n",
    "        # Lista para armazenar as perdas para esta época\n",
    "        losses = []\n",
    "        \n",
    "        # Lista para armazenar as métricas IOU para esta época\n",
    "        train_iou = []\n",
    "        \n",
    "        # Verifica se um programador de taxa de aprendizado foi fornecido\n",
    "        if lr_scheduler:\n",
    "            \n",
    "            # Fator inicial para o aquecimento da taxa de aprendizado\n",
    "            warmup_factor = 1.0 / 100\n",
    "            \n",
    "            # Número de iterações para o aquecimento\n",
    "            warmup_iters = min(100, len(train_loader) - 1)\n",
    "            \n",
    "            # Aplica o aquecimento ao agendador da taxa de aprendizado\n",
    "            lr_scheduler = warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor)\n",
    "        \n",
    "        # Itera sobre o conjunto de treinamento\n",
    "        for i_step, (data, target) in enumerate(tqdm(train_loader)):\n",
    "            \n",
    "            # Move os dados e os rótulos para o device\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            \n",
    "            # Realiza a inferência para gerar previsões\n",
    "            outputs = model(data)\n",
    "            \n",
    "            # Binariza as saídas do modelo com base em um limiar\n",
    "            out_cut = np.copy(outputs.data.cpu().numpy())\n",
    "            out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n",
    "            out_cut[np.nonzero(out_cut >= 0.5)] = 1.0\n",
    "            \n",
    "            # Calcula a métrica DICE para as previsões\n",
    "            train_dice = dice_coef_metric(out_cut, target.data.cpu().numpy())\n",
    "            \n",
    "            # Calcula a perda\n",
    "            loss = train_loss(outputs, target)\n",
    "            \n",
    "            # Adiciona a perda e o IOU às listas correspondentes\n",
    "            losses.append(loss.item())\n",
    "            train_iou.append(train_dice)\n",
    "            \n",
    "            # Zera os gradientes acumulados\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Calcula os gradientes com base na perda\n",
    "            loss.backward()\n",
    "            \n",
    "            # Atualiza os parâmetros do modelo\n",
    "            optimizer.step()\n",
    "    \n",
    "            # Atualiza a taxa de aprendizado se um agendador foi fornecido\n",
    "            if lr_scheduler:\n",
    "                lr_scheduler.step()\n",
    "                \n",
    "        # Calcula a métrica IOU no conjunto de validação\n",
    "        val_mean_iou = compute_iou(model, val_loader)\n",
    "        \n",
    "        # Armazena as métricas e a perda para esta época\n",
    "        loss_history.append(np.array(losses).mean())\n",
    "        train_history.append(np.array(train_iou).mean())\n",
    "        val_history.append(val_mean_iou)\n",
    "        \n",
    "        # Aplica o critério de parada antecipada (early stopping)\n",
    "        early_stopping(np.array(losses).mean(), val_mean_iou)\n",
    "        \n",
    "        # Verifica se o critério de parada antecipada foi atingido\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping na epoch:\", i)\n",
    "            break\n",
    "        \n",
    "        # Exibe as métricas e a perda para esta época\n",
    "        print(\"Epoch [%d]\" % (epoch))\n",
    "        print(\"Erro Médio em Treino:\", np.array(losses).mean(), \n",
    "              \"\\nDICE Médio em Treino:\", np.array(train_iou).mean(), \n",
    "              \"\\nDICE Médio em Validação:\", val_mean_iou)\n",
    "        \n",
    "    print(\"\\nTreinamento Concluído!\\n\")\n",
    "    \n",
    "    # Retorna os históricos de perda e métricas\n",
    "    return loss_history, train_history, val_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otimizador\n",
    "\n",
    "O otimizador torch.optim.Adamax é uma variação do otimizador Adam no PyTorch. Enquanto o otimizador Adam utiliza estimativas do primeiro momento (a média) e do segundo momento (a variância não centralizada) das gradientes, o Adamax apenas utiliza uma estimativa do infinito momento (norma máxima) das gradientes. Esta abordagem foi introduzida na mesma publicação original do Adam e é considerada uma variante que pode ser mais robusta em alguns cenários em relação às estimativas do segundo momento do otimizador Adam.\n",
    "\n",
    "De maneira mais técnica, enquanto o otimizador Adam usa a norma L2 dos gradientes para escalar a taxa de aprendizado, o Adamax usa a norma L∞ (norma infinita).\n",
    "\n",
    "Os hiperparâmetros para o otimizador Adamax são semelhantes aos do Adam. A fórmula de atualização para o Adamax é diferente, mas ele ainda possui parâmetros como a taxa de aprendizado (lr), os coeficientes de decaimento (betas) e um termo para estabilidade numérica (eps).\n",
    "\n",
    "Na prática, embora o Adam seja mais popular e frequentemente mostre um desempenho melhor em uma ampla variedade de tarefas, o Adamax pode ser útil em cenários onde o Adam é instável ou não converge bem. Vale a pena experimentar ambas as variações quando você estiver otimizando um modelo de Deep Learning para entender qual funciona melhor para sua aplicação específica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T11:21:51.261762Z",
     "iopub.status.busy": "2023-01-19T11:21:51.261349Z",
     "iopub.status.idle": "2023-01-19T11:21:51.272433Z",
     "shell.execute_reply": "2023-01-19T11:21:51.271500Z",
     "shell.execute_reply.started": "2023-01-19T11:21:51.261726Z"
    }
   },
   "outputs": [],
   "source": [
    "# Otimizador\n",
    "unet_optimizer = torch.optim.Adamax(modelo_unet_padrao.parameters(), weight_decay = 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de épocas\n",
    "num_ep = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "unet_loss_history, unet_train_history, unet_val_history = treina_modelo(\"UNet_Padrao\", \n",
    "                                                                        modelo_unet_padrao, \n",
    "                                                                        dl_treino, \n",
    "                                                                        dl_valid, \n",
    "                                                                        bce_dice_loss, \n",
    "                                                                        unet_optimizer, \n",
    "                                                                        False, \n",
    "                                                                        num_ep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação do Modelo em Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T12:08:55.083557Z",
     "iopub.status.busy": "2023-01-19T12:08:55.083249Z",
     "iopub.status.idle": "2023-01-19T12:08:55.090824Z",
     "shell.execute_reply": "2023-01-19T12:08:55.089467Z",
     "shell.execute_reply.started": "2023-01-19T12:08:55.083528Z"
    }
   },
   "outputs": [],
   "source": [
    "# Função para plot do histórico de treino e validação\n",
    "def plot_model_history(model_name, train_history, val_history, num_epochs):\n",
    "    \n",
    "    x = np.arange(num_epochs)\n",
    "    fig = plt.figure(figsize = (10, 6))\n",
    "    plt.plot(x, train_history, label = 'DICE em Treino', lw = 3, c = \"springgreen\")\n",
    "    plt.plot(x, val_history, label = 'DICE em Validação', lw = 3, c = \"deeppink\")\n",
    "    plt.title(f\"{model_name}\", fontsize = 15)\n",
    "    plt.legend(fontsize = 12)\n",
    "    plt.xlabel(\"Epoch\", fontsize = 15)\n",
    "    plt.ylabel(\"DICE\", fontsize = 15)\n",
    "    fn = str(int(time.time())) + \".png\"\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T12:08:55.092815Z",
     "iopub.status.busy": "2023-01-19T12:08:55.092251Z",
     "iopub.status.idle": "2023-01-19T12:08:55.323936Z",
     "shell.execute_reply": "2023-01-19T12:08:55.323041Z",
     "shell.execute_reply.started": "2023-01-19T12:08:55.092777Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_model_history(\"UNet_Padrao\", unet_train_history, unet_val_history, num_ep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação nos Dados de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula o IoU em teste\n",
    "test_iou = compute_iou(modelo_unet_padrao, dl_teste)\n",
    "print(f\"\"\"Modelo UNet Padrão\\nMédia de IoU nas imagens de teste - {np.around(test_iou, 2)*100}%\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrai uma imagem de teste de forma aleatória. Extraímos imagens com diagnóstico igual a 1 (o que nos interessa)\n",
    "amostra_teste = df_teste[df_teste[\"diagnostico\"] == 1].sample(1).values[0]\n",
    "print(amostra_teste)\n",
    "\n",
    "# Carrega imagem e máscara\n",
    "image = cv2.resize(cv2.imread(amostra_teste[1]), (128, 128))\n",
    "mask = cv2.resize(cv2.imread(amostra_teste[2]), (128, 128))\n",
    "\n",
    "# Faz a previsão (os pixels da máscara são a previsão do modelo)\n",
    "pred = torch.tensor(image.astype(np.float32) / 255.).unsqueeze(0).permute(0,3,1,2)\n",
    "pred = modelo_unet_padrao(pred.to(device))\n",
    "pred = pred.detach().cpu().numpy()[0, 0, :, :]\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (8, 8))\n",
    "\n",
    "ax[0].imshow(image)\n",
    "ax[0].set_title(\"Imagem Original\")\n",
    "\n",
    "ax[1].imshow(pred)\n",
    "ax[1].set_title(\"Máscara Prevista\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelagem com Arquitetura U-Net e ResNet Backbone\n",
    "\n",
    "https://arxiv.org/pdf/2004.05645.pdf\n",
    "\n",
    "https://arxiv.org/abs/2204.12084"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe ConvRelu\n",
    "class ConvRelu(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, kernel, padding):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.convrelu = nn.Sequential(nn.Conv2d(in_channels, \n",
    "                                                out_channels, \n",
    "                                                kernel, \n",
    "                                                padding = padding),\n",
    "                                      nn.ReLU(inplace = True))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.convrelu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe DecoderBlock\n",
    "class DecoderBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = ConvRelu(in_channels, in_channels//4, 1, 0)\n",
    "        \n",
    "        self.deconv = nn.ConvTranspose2d(in_channels//4, \n",
    "                                         in_channels//4, \n",
    "                                         kernel_size = 4, \n",
    "                                         stride = 2, \n",
    "                                         padding = 1, \n",
    "                                         output_padding = 0)\n",
    "        \n",
    "        self.conv2 = ConvRelu(in_channels//4, out_channels, 1, 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.deconv(x)\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe ResNeXtUNet\n",
    "class ResNeXtUNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_classes = 1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.base_model = resnext50_32x4d(pretrained = True)\n",
    "        self.base_layers = list(self.base_model.children())\n",
    "        filters = [4*64, 4*128, 4*256, 4*512]\n",
    "        \n",
    "        self.encoder0 = nn.Sequential(*self.base_layers[:3])\n",
    "        self.encoder1 = nn.Sequential(*self.base_layers[4])\n",
    "        self.encoder2 = nn.Sequential(*self.base_layers[5])\n",
    "        self.encoder3 = nn.Sequential(*self.base_layers[6])\n",
    "        self.encoder4 = nn.Sequential(*self.base_layers[7])\n",
    "        \n",
    "        self.decoder4 = DecoderBlock(filters[3], filters[2])\n",
    "        self.decoder3 = DecoderBlock(filters[2], filters[1])\n",
    "        self.decoder2 = DecoderBlock(filters[1], filters[0])\n",
    "        self.decoder1 = DecoderBlock(filters[0], filters[0])\n",
    "        \n",
    "        self.last_conv0 = ConvRelu(256, 128, 3, 1)\n",
    "        self.last_conv1 = nn.Conv2d(128, n_classes, 3, padding = 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.encoder0(x)\n",
    "        e1 = self.encoder1(x)\n",
    "        e2 = self.encoder2(e1)\n",
    "        e3 = self.encoder3(e2)\n",
    "        e4 = self.encoder4(e3)\n",
    "        \n",
    "        d4 = self.decoder4(e4) + e3\n",
    "        d3 = self.decoder3(d4) + e2\n",
    "        d2 = self.decoder2(d3) + e1\n",
    "        d1 = self.decoder1(d2)\n",
    "        \n",
    "        out = self.last_conv0(d1)\n",
    "        out = self.last_conv1(out)\n",
    "        \n",
    "        out = torch.sigmoid(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria instância da classe\n",
    "modelo_resnet_unet = ResNeXtUNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arquitetura final\n",
    "modelo_resnet_unet.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T12:40:59.738052Z",
     "iopub.status.busy": "2023-01-19T12:40:59.737458Z",
     "iopub.status.idle": "2023-01-19T12:40:59.749273Z",
     "shell.execute_reply": "2023-01-19T12:40:59.748256Z",
     "shell.execute_reply.started": "2023-01-19T12:40:59.737996Z"
    }
   },
   "outputs": [],
   "source": [
    "# Otimizador\n",
    "resnextunet_optimizer = torch.optim.Adamax(modelo_resnet_unet.parameters(), weight_decay = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de épocas\n",
    "num_ep = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T12:40:59.751546Z",
     "iopub.status.busy": "2023-01-19T12:40:59.750512Z",
     "iopub.status.idle": "2023-01-19T14:18:28.975862Z",
     "shell.execute_reply": "2023-01-19T14:18:28.974280Z",
     "shell.execute_reply.started": "2023-01-19T12:40:59.751507Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "resnextunet_lh, resnextunet_th, resnextunet_vh = treina_modelo(\"ResNeXtUNet\", \n",
    "                                                               modelo_resnet_unet, \n",
    "                                                               dl_treino, \n",
    "                                                               dl_valid, \n",
    "                                                               bce_dice_loss, \n",
    "                                                               resnextunet_optimizer, \n",
    "                                                               False, \n",
    "                                                               num_ep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação do Modelo em Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_history(\"ResNeXtUNet\", resnextunet_th, resnextunet_vh, num_ep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação nos Dados de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T14:18:37.402625Z",
     "iopub.status.busy": "2023-01-19T14:18:37.401793Z",
     "iopub.status.idle": "2023-01-19T14:18:42.038869Z",
     "shell.execute_reply": "2023-01-19T14:18:42.037203Z",
     "shell.execute_reply.started": "2023-01-19T14:18:37.402582Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calcula o IoU nos dados de teste\n",
    "test_iou = compute_iou(modelo_resnet_unet, dl_teste)\n",
    "print(f\"\"\"Modelo ResNeXtUNet\\nMédia de IoU nos dados de teste - {np.around(test_iou, 2)*100}%\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T14:18:42.042578Z",
     "iopub.status.busy": "2023-01-19T14:18:42.041847Z",
     "iopub.status.idle": "2023-01-19T14:18:43.569093Z",
     "shell.execute_reply": "2023-01-19T14:18:43.568116Z",
     "shell.execute_reply.started": "2023-01-19T14:18:42.042533Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extrai uma imagem de teste de forma aleatória. Extraímos imagens com diagnóstico igual a 1 (o que nos interessa)\n",
    "amostra_teste = df_teste[df_teste[\"diagnostico\"] == 1].sample(1).values[0]\n",
    "print(amostra_teste)\n",
    "\n",
    "# Carrega imagem e máscara\n",
    "image = cv2.resize(cv2.imread(amostra_teste[1]), (128, 128))\n",
    "mask = cv2.resize(cv2.imread(amostra_teste[2]), (128, 128))\n",
    "\n",
    "# Faz a previsão (os pixels da máscara são a previsão do modelo)\n",
    "pred = torch.tensor(image.astype(np.float32) / 255.).unsqueeze(0).permute(0,3,1,2)\n",
    "pred = modelo_resnet_unet(pred.to(device))\n",
    "pred = pred.detach().cpu().numpy()[0, 0, :, :]\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (8, 8))\n",
    "\n",
    "ax[0].imshow(image)\n",
    "ax[0].set_title(\"Imagem Original\")\n",
    "\n",
    "ax[1].imshow(pred)\n",
    "ax[1].set_title(\"Máscara Prevista\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
